{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "In this notebook, sentence augmentations examples for both aggregation methods are shown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make imports from parent directory possible\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "# Disable verbose warnings\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import logging\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "\n",
    "from transformers.models.bert.tokenization_bert import BertTokenizer\n",
    "from transformers.models.bert.modeling_bert import BertModel\n",
    "\n",
    "from transformers.models.roberta.tokenization_roberta import RobertaTokenizer\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "from attention_driven_dropout import AttentionDrivenDropout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Tokenizer and Model\n",
    "You can instantiate either the BERT or RoBERTA tokenizer and model. We show the output for both base models here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta_model = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentences = [\n",
    "    \"We should go to the small italian restaurant again!\",\n",
    "    \"Two big dogs are running fast in the park.\",\n",
    "    \"Mary helped John to style his new apartment.\",\n",
    "    \"A brown bear is eating a small fish.\",\n",
    "]\n",
    "\n",
    "input_ids_bert = torch.tensor(bert_tokenizer(example_sentences, padding=True).input_ids)\n",
    "input_ids_roberta = torch.tensor(roberta_tokenizer(example_sentences, padding=True).input_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for printing the output of the augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bert(input_ids, altered_input_ids, scores):\n",
    "    for i in range(len(input_ids)):\n",
    "        print(\"Original sentence:\", bert_tokenizer.decode(input_ids[i]))\n",
    "        print(\"Altered sentence:\", bert_tokenizer.decode(altered_input_ids[i]))\n",
    "        min_index = scores[i][scores[i] > 0].min(0).indices\n",
    "        print(f\"Removed: {bert_tokenizer.decode(input_ids[i][min_index])} ({scores[i][min_index]})\")\n",
    "        print()\n",
    "    \n",
    "def print_roberta(input_ids, altered_input_ids, scores):\n",
    "    for i in range(len(input_ids)):\n",
    "        print(\"Original sentence:\", roberta_tokenizer.decode(input_ids[i]))\n",
    "        print(\"Altered sentence:\", roberta_tokenizer.decode(altered_input_ids[i]))\n",
    "        min_index = scores[i][scores[i] > 0].min(0).indices\n",
    "        print(f\"Removed: {roberta_tokenizer.decode(input_ids[i][min_index])} ({scores[i][min_index]})\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Naive Aggregation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: [CLS] we should go to the small italian restaurant again! [SEP]\n",
      "Altered sentence: [CLS] we should go to the small restaurant again! [SEP] [PAD]\n",
      "Removed: i t a l i a n (57.876129150390625)\n",
      "\n",
      "Original sentence: [CLS] two big dogs are running fast in the park. [SEP]\n",
      "Altered sentence: [CLS] two dogs are running fast in the park. [SEP] [PAD]\n",
      "Removed: b i g (54.35097885131836)\n",
      "\n",
      "Original sentence: [CLS] mary helped john to style his new apartment. [SEP] [PAD]\n",
      "Altered sentence: [CLS] mary helped john to style his apartment. [SEP] [PAD] [PAD]\n",
      "Removed: n e w (55.61100769042969)\n",
      "\n",
      "Original sentence: [CLS] a brown bear is eating a small fish. [SEP] [PAD]\n",
      "Altered sentence: [CLS] a brown bear is eating a fish. [SEP] [PAD] [PAD]\n",
      "Removed: s m a l l (51.31556701660156)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_add = AttentionDrivenDropout(bert_model, n_dropout=1, min_tokens=1)\n",
    "naive_output_ids, scores = naive_add(input_ids_bert, return_scores=True, num_sent=1)\n",
    "\n",
    "print_bert(input_ids_bert, naive_output_ids, scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: <s>Two big dogs are running fast in the park.</s><pad>\n",
      "Altered sentence: <s>Two dogs are running fast in the park.</s><pad><pad>\n",
      "Removed:  big (49.18559265136719)\n",
      "\n",
      "Original sentence: <s>Mary helped John to style his new apartment.</s><pad><pad>\n",
      "Altered sentence: <s>Mary helped John to style new apartment.</s><pad><pad><pad>\n",
      "Removed:  his (54.62554931640625)\n",
      "\n",
      "Original sentence: <s>A brown bear is eating a small fish.</s><pad><pad>\n",
      "Altered sentence: <s>A bear is eating a small fish.</s><pad><pad><pad>\n",
      "Removed:  brown (48.095272064208984)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_add = AttentionDrivenDropout(roberta_model, n_dropout=1, min_tokens=1)\n",
    "naive_output_ids, scores = naive_add(input_ids_roberta[1:], return_scores=True, num_sent=1)\n",
    "\n",
    "print_roberta(input_ids_roberta[1:], naive_output_ids, scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Attention Rollout Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: [CLS] we should go to the small italian restaurant again! [SEP]\n",
      "Altered sentence: [CLS] we should go to the italian restaurant again! [SEP] [PAD]\n",
      "Removed: s m a l l (5.803347110748291)\n",
      "\n",
      "Original sentence: [CLS] two big dogs are running fast in the park. [SEP]\n",
      "Altered sentence: [CLS] two dogs are running fast in the park. [SEP] [PAD]\n",
      "Removed: b i g (5.9078240394592285)\n",
      "\n",
      "Original sentence: [CLS] mary helped john to style his new apartment. [SEP] [PAD]\n",
      "Altered sentence: [CLS] mary helped to style his new apartment. [SEP] [PAD] [PAD]\n",
      "Removed: j o h n (5.947506904602051)\n",
      "\n",
      "Original sentence: [CLS] a brown bear is eating a small fish. [SEP] [PAD]\n",
      "Altered sentence: [CLS] a bear is eating a small fish. [SEP] [PAD] [PAD]\n",
      "Removed: b r o w n (5.942243576049805)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_rollout = AttentionDrivenDropout(bert_model, n_dropout=1, min_tokens=1, summation_method=\"rollout\")\n",
    "rollout_output_ids, scores = add_rollout(input_ids_bert, return_scores=True, num_sent=1)\n",
    "\n",
    "print_bert(input_ids_bert, rollout_output_ids, scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: <s>We should go to the small italian restaurant again!</s>\n",
      "Altered sentence: <s>We should go to the italian restaurant again!</s><pad>\n",
      "Removed:  small (6.072007179260254)\n",
      "\n",
      "Original sentence: <s>Two big dogs are running fast in the park.</s><pad>\n",
      "Altered sentence: <s>Two big dogs are fast in the park.</s><pad><pad>\n",
      "Removed:  running (5.800328731536865)\n",
      "\n",
      "Original sentence: <s>Mary helped John to style his new apartment.</s><pad><pad>\n",
      "Altered sentence: <s>Mary helped to style his new apartment.</s><pad><pad><pad>\n",
      "Removed:  John (5.892853260040283)\n",
      "\n",
      "Original sentence: <s>A brown bear is eating a small fish.</s><pad><pad>\n",
      "Altered sentence: <s>A brown bear is eating a fish.</s><pad><pad><pad>\n",
      "Removed:  small (6.218420028686523)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_rollout = AttentionDrivenDropout(roberta_model, n_dropout=1, min_tokens=1, summation_method=\"rollout\")\n",
    "rollout_output_ids, scores = add_rollout(input_ids_roberta, return_scores=True, num_sent=1)\n",
    "\n",
    "print_roberta(input_ids_roberta, rollout_output_ids, scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7db4c85829fc372109fe531063760a7723c9ecb78d3f81bdc744b7386f7e42a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
